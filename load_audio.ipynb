{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8cc45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_dataset import paths, load_helpers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.data import AUTOTUNE\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24e01e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\"dataset\": \"\", \"augment\":False, \"type\":\"layers\"}  # type = [\"layers\", \"ops\"]\n",
    "ValidAudios = [\"*.wav\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6eee85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the batch size\n",
    "BATCH_SIZE = 8\n",
    "# grabs all image paths\n",
    "audioPaths = list(paths.list_audios(args[\"dataset\"]))\n",
    "# build our dataset and data input pipeline\n",
    "print(\"[INFO] loading the dataset...\")\n",
    "ds = tf.data.Dataset.from_tensor_slices(audioPaths)\n",
    "ds = (ds\n",
    "\t.shuffle(len(audioPaths), seed=42)\n",
    "\t.map(load_helpers.load_images, num_parallel_calls=AUTOTUNE)\n",
    "\t.cache()\n",
    "\t.batch(BATCH_SIZE)\n",
    "    )\n",
    "\n",
    "# check if we should apply data augmentation\n",
    "if args[\"augment\"]:\n",
    "\t# check if we will be using layers to perform data augmentation\n",
    "\tif args[\"type\"] == \"layers\":\n",
    "\t\t# initialize our sequential data augmentation pipeline\n",
    "\t\taug = tf.keras.Sequential([\n",
    "\t\t\tpreprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "\t\t\tpreprocessing.RandomZoom(\n",
    "\t\t\t\theight_factor=(-0.05, -0.15),\n",
    "\t\t\t\twidth_factor=(-0.05, -0.15)),\n",
    "\t\t\tpreprocessing.RandomRotation(0.3)\n",
    "\t\t])\n",
    "\t\t# add data augmentation to our data input pipeline\n",
    "\t\tds = (ds\n",
    "\t\t\t.map(lambda x, y: augment_using_layers(x, y, aug),\n",
    "\t\t\t\tnum_parallel_calls=AUTOTUNE)\n",
    "\t\t)\n",
    "\t# otherwise, we will be using TensorFlow image operations to\n",
    "\t# perform data augmentation\n",
    "\telse:\n",
    "\t\t# add data augmentation to our data input pipeline\n",
    "\t\tds = (ds\n",
    "\t\t\t.map(augment_using_ops, num_parallel_calls=AUTOTUNE)\n",
    "\t\t)\n",
    "\n",
    "# complete our data input pipeline\n",
    "ds = (ds\n",
    "\t.prefetch(AUTOTUNE)\n",
    ")\n",
    "# grab a batch of data from our dataset\n",
    "batch = next(iter(ds))\n",
    "\n",
    "# initialize a figure\n",
    "print(\"[INFO] visualizing the first batch of the dataset...\")\n",
    "title = \"With data augmentation {}\".format(\n",
    "\t\"applied ({})\".format(args[\"type\"]) if args[\"augment\"] else \\\n",
    "\t\"not applied\")\n",
    "fig = plt.figure(figsize=(BATCH_SIZE, BATCH_SIZE))\n",
    "fig.suptitle(title)\n",
    "# loop over the batch size\n",
    "for i in range(0, BATCH_SIZE):\n",
    "\t# grab the image and label from the batch\n",
    "\t(image, label) = (batch[0][i], batch[1][i])\n",
    "\t# create a subplot and plot the image and label\n",
    "\tax = plt.subplot(2, 4, i + 1)\n",
    "\tplt.imshow(image.numpy())\n",
    "\tplt.title(label.numpy().decode(\"UTF-8\"))\n",
    "\tplt.axis(\"off\")\n",
    "# show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d3d88f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AudioIOTensor: shape=[53476     1], dtype=<dtype: 'int16'>, rate=16000>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_io as tfio\n",
    "filepath = \"4persons/a_1.wav\"\n",
    "audio = tfio.audio.AudioIOTensor(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9155b609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53476, 1)\n"
     ]
    }
   ],
   "source": [
    "print(audio.to_tensor().numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf258de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
