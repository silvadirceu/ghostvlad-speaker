Model: "vggvox_resnet2D_amsoftmax_gvlad"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input (InputLayer)              [(None, 257, 250, 1) 0                                            
__________________________________________________________________________________________________
conv1_1/3x3_s1 (Conv2D)         (None, 257, 250, 64) 3136        input[0][0]                      
__________________________________________________________________________________________________
conv1_1/3x3_s1/bn (BatchNormali (None, 257, 250, 64) 256         conv1_1/3x3_s1[0][0]             
__________________________________________________________________________________________________
activation_488 (Activation)     (None, 257, 250, 64) 0           conv1_1/3x3_s1/bn[0][0]          
__________________________________________________________________________________________________
max_pooling2d_24 (MaxPooling2D) (None, 128, 125, 64) 0           activation_488[0][0]             
__________________________________________________________________________________________________
conv2_a_1x1_reduce (Conv2D)     (None, 128, 125, 48) 3072        max_pooling2d_24[0][0]           
__________________________________________________________________________________________________
conv2_a_1x1_reduce/bn (BatchNor (None, 128, 125, 48) 192         conv2_a_1x1_reduce[0][0]         
__________________________________________________________________________________________________
activation_489 (Activation)     (None, 128, 125, 48) 0           conv2_a_1x1_reduce/bn[0][0]      
__________________________________________________________________________________________________
conv2_a_3x3 (Conv2D)            (None, 128, 125, 48) 20736       activation_489[0][0]             
__________________________________________________________________________________________________
conv2_a_3x3/bn (BatchNormalizat (None, 128, 125, 48) 192         conv2_a_3x3[0][0]                
__________________________________________________________________________________________________
activation_490 (Activation)     (None, 128, 125, 48) 0           conv2_a_3x3/bn[0][0]             
__________________________________________________________________________________________________
conv2_a_1x1_increase (Conv2D)   (None, 128, 125, 96) 4608        activation_490[0][0]             
__________________________________________________________________________________________________
conv2_a_1x1_proj (Conv2D)       (None, 128, 125, 96) 6144        max_pooling2d_24[0][0]           
__________________________________________________________________________________________________
conv2_a_1x1_increase/bn (BatchN (None, 128, 125, 96) 384         conv2_a_1x1_increase[0][0]       
__________________________________________________________________________________________________
conv2_a_1x1_proj/bn (BatchNorma (None, 128, 125, 96) 384         conv2_a_1x1_proj[0][0]           
__________________________________________________________________________________________________
add_154 (Add)                   (None, 128, 125, 96) 0           conv2_a_1x1_increase/bn[0][0]    
                                                                 conv2_a_1x1_proj/bn[0][0]        
__________________________________________________________________________________________________
activation_491 (Activation)     (None, 128, 125, 96) 0           add_154[0][0]                    
__________________________________________________________________________________________________
conv2_b_1x1_reduce (Conv2D)     (None, 128, 125, 48) 4608        activation_491[0][0]             
__________________________________________________________________________________________________
conv2_b_1x1_reduce/bn (BatchNor (None, 128, 125, 48) 192         conv2_b_1x1_reduce[0][0]         
__________________________________________________________________________________________________
activation_492 (Activation)     (None, 128, 125, 48) 0           conv2_b_1x1_reduce/bn[0][0]      
__________________________________________________________________________________________________
conv2_b_3x3 (Conv2D)            (None, 128, 125, 48) 20736       activation_492[0][0]             
__________________________________________________________________________________________________
conv2_b_3x3/bn (BatchNormalizat (None, 128, 125, 48) 192         conv2_b_3x3[0][0]                
__________________________________________________________________________________________________
activation_493 (Activation)     (None, 128, 125, 48) 0           conv2_b_3x3/bn[0][0]             
__________________________________________________________________________________________________
conv2_b_1x1_increase (Conv2D)   (None, 128, 125, 96) 4608        activation_493[0][0]             
__________________________________________________________________________________________________
conv2_b_1x1_increase/bn (BatchN (None, 128, 125, 96) 384         conv2_b_1x1_increase[0][0]       
__________________________________________________________________________________________________
add_155 (Add)                   (None, 128, 125, 96) 0           conv2_b_1x1_increase/bn[0][0]    
                                                                 activation_491[0][0]             
__________________________________________________________________________________________________
activation_494 (Activation)     (None, 128, 125, 96) 0           add_155[0][0]                    
__________________________________________________________________________________________________
conv3_a_1x1_reduce (Conv2D)     (None, 64, 63, 96)   9216        activation_494[0][0]             
__________________________________________________________________________________________________
conv3_a_1x1_reduce/bn (BatchNor (None, 64, 63, 96)   384         conv3_a_1x1_reduce[0][0]         
__________________________________________________________________________________________________
activation_495 (Activation)     (None, 64, 63, 96)   0           conv3_a_1x1_reduce/bn[0][0]      
__________________________________________________________________________________________________
conv3_a_3x3 (Conv2D)            (None, 64, 63, 96)   82944       activation_495[0][0]             
__________________________________________________________________________________________________
conv3_a_3x3/bn (BatchNormalizat (None, 64, 63, 96)   384         conv3_a_3x3[0][0]                
__________________________________________________________________________________________________
activation_496 (Activation)     (None, 64, 63, 96)   0           conv3_a_3x3/bn[0][0]             
__________________________________________________________________________________________________
conv3_a_1x1_increase (Conv2D)   (None, 64, 63, 128)  12288       activation_496[0][0]             
__________________________________________________________________________________________________
conv3_a_1x1_proj (Conv2D)       (None, 64, 63, 128)  12288       activation_494[0][0]             
__________________________________________________________________________________________________
conv3_a_1x1_increase/bn (BatchN (None, 64, 63, 128)  512         conv3_a_1x1_increase[0][0]       
__________________________________________________________________________________________________
conv3_a_1x1_proj/bn (BatchNorma (None, 64, 63, 128)  512         conv3_a_1x1_proj[0][0]           
__________________________________________________________________________________________________
add_156 (Add)                   (None, 64, 63, 128)  0           conv3_a_1x1_increase/bn[0][0]    
                                                                 conv3_a_1x1_proj/bn[0][0]        
__________________________________________________________________________________________________
activation_497 (Activation)     (None, 64, 63, 128)  0           add_156[0][0]                    
__________________________________________________________________________________________________
conv3_b_1x1_reduce (Conv2D)     (None, 64, 63, 96)   12288       activation_497[0][0]             
__________________________________________________________________________________________________
conv3_b_1x1_reduce/bn (BatchNor (None, 64, 63, 96)   384         conv3_b_1x1_reduce[0][0]         
__________________________________________________________________________________________________
activation_498 (Activation)     (None, 64, 63, 96)   0           conv3_b_1x1_reduce/bn[0][0]      
__________________________________________________________________________________________________
conv3_b_3x3 (Conv2D)            (None, 64, 63, 96)   82944       activation_498[0][0]             
__________________________________________________________________________________________________
conv3_b_3x3/bn (BatchNormalizat (None, 64, 63, 96)   384         conv3_b_3x3[0][0]                
__________________________________________________________________________________________________
activation_499 (Activation)     (None, 64, 63, 96)   0           conv3_b_3x3/bn[0][0]             
__________________________________________________________________________________________________
conv3_b_1x1_increase (Conv2D)   (None, 64, 63, 128)  12288       activation_499[0][0]             
__________________________________________________________________________________________________
conv3_b_1x1_increase/bn (BatchN (None, 64, 63, 128)  512         conv3_b_1x1_increase[0][0]       
__________________________________________________________________________________________________
add_157 (Add)                   (None, 64, 63, 128)  0           conv3_b_1x1_increase/bn[0][0]    
                                                                 activation_497[0][0]             
__________________________________________________________________________________________________
activation_500 (Activation)     (None, 64, 63, 128)  0           add_157[0][0]                    
__________________________________________________________________________________________________
conv3_c_1x1_reduce (Conv2D)     (None, 64, 63, 96)   12288       activation_500[0][0]             
__________________________________________________________________________________________________
conv3_c_1x1_reduce/bn (BatchNor (None, 64, 63, 96)   384         conv3_c_1x1_reduce[0][0]         
__________________________________________________________________________________________________
activation_501 (Activation)     (None, 64, 63, 96)   0           conv3_c_1x1_reduce/bn[0][0]      
__________________________________________________________________________________________________
conv3_c_3x3 (Conv2D)            (None, 64, 63, 96)   82944       activation_501[0][0]             
__________________________________________________________________________________________________
conv3_c_3x3/bn (BatchNormalizat (None, 64, 63, 96)   384         conv3_c_3x3[0][0]                
__________________________________________________________________________________________________
activation_502 (Activation)     (None, 64, 63, 96)   0           conv3_c_3x3/bn[0][0]             
__________________________________________________________________________________________________
conv3_c_1x1_increase (Conv2D)   (None, 64, 63, 128)  12288       activation_502[0][0]             
__________________________________________________________________________________________________
conv3_c_1x1_increase/bn (BatchN (None, 64, 63, 128)  512         conv3_c_1x1_increase[0][0]       
__________________________________________________________________________________________________
add_158 (Add)                   (None, 64, 63, 128)  0           conv3_c_1x1_increase/bn[0][0]    
                                                                 activation_500[0][0]             
__________________________________________________________________________________________________
activation_503 (Activation)     (None, 64, 63, 128)  0           add_158[0][0]                    
__________________________________________________________________________________________________
conv4_a_1x1_reduce (Conv2D)     (None, 32, 32, 128)  16384       activation_503[0][0]             
__________________________________________________________________________________________________
conv4_a_1x1_reduce/bn (BatchNor (None, 32, 32, 128)  512         conv4_a_1x1_reduce[0][0]         
__________________________________________________________________________________________________
activation_504 (Activation)     (None, 32, 32, 128)  0           conv4_a_1x1_reduce/bn[0][0]      
__________________________________________________________________________________________________
conv4_a_3x3 (Conv2D)            (None, 32, 32, 128)  147456      activation_504[0][0]             
__________________________________________________________________________________________________
conv4_a_3x3/bn (BatchNormalizat (None, 32, 32, 128)  512         conv4_a_3x3[0][0]                
__________________________________________________________________________________________________
activation_505 (Activation)     (None, 32, 32, 128)  0           conv4_a_3x3/bn[0][0]             
__________________________________________________________________________________________________
conv4_a_1x1_increase (Conv2D)   (None, 32, 32, 256)  32768       activation_505[0][0]             
__________________________________________________________________________________________________
conv4_a_1x1_proj (Conv2D)       (None, 32, 32, 256)  32768       activation_503[0][0]             
__________________________________________________________________________________________________
conv4_a_1x1_increase/bn (BatchN (None, 32, 32, 256)  1024        conv4_a_1x1_increase[0][0]       
__________________________________________________________________________________________________
conv4_a_1x1_proj/bn (BatchNorma (None, 32, 32, 256)  1024        conv4_a_1x1_proj[0][0]           
__________________________________________________________________________________________________
add_159 (Add)                   (None, 32, 32, 256)  0           conv4_a_1x1_increase/bn[0][0]    
                                                                 conv4_a_1x1_proj/bn[0][0]        
__________________________________________________________________________________________________
activation_506 (Activation)     (None, 32, 32, 256)  0           add_159[0][0]                    
__________________________________________________________________________________________________
conv4_b_1x1_reduce (Conv2D)     (None, 32, 32, 128)  32768       activation_506[0][0]             
__________________________________________________________________________________________________
conv4_b_1x1_reduce/bn (BatchNor (None, 32, 32, 128)  512         conv4_b_1x1_reduce[0][0]         
__________________________________________________________________________________________________
activation_507 (Activation)     (None, 32, 32, 128)  0           conv4_b_1x1_reduce/bn[0][0]      
__________________________________________________________________________________________________
conv4_b_3x3 (Conv2D)            (None, 32, 32, 128)  147456      activation_507[0][0]             
__________________________________________________________________________________________________
conv4_b_3x3/bn (BatchNormalizat (None, 32, 32, 128)  512         conv4_b_3x3[0][0]                
__________________________________________________________________________________________________
activation_508 (Activation)     (None, 32, 32, 128)  0           conv4_b_3x3/bn[0][0]             
__________________________________________________________________________________________________
conv4_b_1x1_increase (Conv2D)   (None, 32, 32, 256)  32768       activation_508[0][0]             
__________________________________________________________________________________________________
conv4_b_1x1_increase/bn (BatchN (None, 32, 32, 256)  1024        conv4_b_1x1_increase[0][0]       
__________________________________________________________________________________________________
add_160 (Add)                   (None, 32, 32, 256)  0           conv4_b_1x1_increase/bn[0][0]    
                                                                 activation_506[0][0]             
__________________________________________________________________________________________________
activation_509 (Activation)     (None, 32, 32, 256)  0           add_160[0][0]                    
__________________________________________________________________________________________________
conv4_c_1x1_reduce (Conv2D)     (None, 32, 32, 128)  32768       activation_509[0][0]             
__________________________________________________________________________________________________
conv4_c_1x1_reduce/bn (BatchNor (None, 32, 32, 128)  512         conv4_c_1x1_reduce[0][0]         
__________________________________________________________________________________________________
activation_510 (Activation)     (None, 32, 32, 128)  0           conv4_c_1x1_reduce/bn[0][0]      
__________________________________________________________________________________________________
conv4_c_3x3 (Conv2D)            (None, 32, 32, 128)  147456      activation_510[0][0]             
__________________________________________________________________________________________________
conv4_c_3x3/bn (BatchNormalizat (None, 32, 32, 128)  512         conv4_c_3x3[0][0]                
__________________________________________________________________________________________________
activation_511 (Activation)     (None, 32, 32, 128)  0           conv4_c_3x3/bn[0][0]             
__________________________________________________________________________________________________
conv4_c_1x1_increase (Conv2D)   (None, 32, 32, 256)  32768       activation_511[0][0]             
__________________________________________________________________________________________________
conv4_c_1x1_increase/bn (BatchN (None, 32, 32, 256)  1024        conv4_c_1x1_increase[0][0]       
__________________________________________________________________________________________________
add_161 (Add)                   (None, 32, 32, 256)  0           conv4_c_1x1_increase/bn[0][0]    
                                                                 activation_509[0][0]             
__________________________________________________________________________________________________
activation_512 (Activation)     (None, 32, 32, 256)  0           add_161[0][0]                    
__________________________________________________________________________________________________
conv5_a_1x1_reduce (Conv2D)     (None, 16, 16, 256)  65536       activation_512[0][0]             
__________________________________________________________________________________________________
conv5_a_1x1_reduce/bn (BatchNor (None, 16, 16, 256)  1024        conv5_a_1x1_reduce[0][0]         
__________________________________________________________________________________________________
activation_513 (Activation)     (None, 16, 16, 256)  0           conv5_a_1x1_reduce/bn[0][0]      
__________________________________________________________________________________________________
conv5_a_3x3 (Conv2D)            (None, 16, 16, 256)  589824      activation_513[0][0]             
__________________________________________________________________________________________________
conv5_a_3x3/bn (BatchNormalizat (None, 16, 16, 256)  1024        conv5_a_3x3[0][0]                
__________________________________________________________________________________________________
activation_514 (Activation)     (None, 16, 16, 256)  0           conv5_a_3x3/bn[0][0]             
__________________________________________________________________________________________________
conv5_a_1x1_increase (Conv2D)   (None, 16, 16, 512)  131072      activation_514[0][0]             
__________________________________________________________________________________________________
conv5_a_1x1_proj (Conv2D)       (None, 16, 16, 512)  131072      activation_512[0][0]             
__________________________________________________________________________________________________
conv5_a_1x1_increase/bn (BatchN (None, 16, 16, 512)  2048        conv5_a_1x1_increase[0][0]       
__________________________________________________________________________________________________
conv5_a_1x1_proj/bn (BatchNorma (None, 16, 16, 512)  2048        conv5_a_1x1_proj[0][0]           
__________________________________________________________________________________________________
add_162 (Add)                   (None, 16, 16, 512)  0           conv5_a_1x1_increase/bn[0][0]    
                                                                 conv5_a_1x1_proj/bn[0][0]        
__________________________________________________________________________________________________
activation_515 (Activation)     (None, 16, 16, 512)  0           add_162[0][0]                    
__________________________________________________________________________________________________
conv5_b_1x1_reduce (Conv2D)     (None, 16, 16, 256)  131072      activation_515[0][0]             
__________________________________________________________________________________________________
conv5_b_1x1_reduce/bn (BatchNor (None, 16, 16, 256)  1024        conv5_b_1x1_reduce[0][0]         
__________________________________________________________________________________________________
activation_516 (Activation)     (None, 16, 16, 256)  0           conv5_b_1x1_reduce/bn[0][0]      
__________________________________________________________________________________________________
conv5_b_3x3 (Conv2D)            (None, 16, 16, 256)  589824      activation_516[0][0]             
__________________________________________________________________________________________________
conv5_b_3x3/bn (BatchNormalizat (None, 16, 16, 256)  1024        conv5_b_3x3[0][0]                
__________________________________________________________________________________________________
activation_517 (Activation)     (None, 16, 16, 256)  0           conv5_b_3x3/bn[0][0]             
__________________________________________________________________________________________________
conv5_b_1x1_increase (Conv2D)   (None, 16, 16, 512)  131072      activation_517[0][0]             
__________________________________________________________________________________________________
conv5_b_1x1_increase/bn (BatchN (None, 16, 16, 512)  2048        conv5_b_1x1_increase[0][0]       
__________________________________________________________________________________________________
add_163 (Add)                   (None, 16, 16, 512)  0           conv5_b_1x1_increase/bn[0][0]    
                                                                 activation_515[0][0]             
__________________________________________________________________________________________________
activation_518 (Activation)     (None, 16, 16, 512)  0           add_163[0][0]                    
__________________________________________________________________________________________________
conv5_c_1x1_reduce (Conv2D)     (None, 16, 16, 256)  131072      activation_518[0][0]             
__________________________________________________________________________________________________
conv5_c_1x1_reduce/bn (BatchNor (None, 16, 16, 256)  1024        conv5_c_1x1_reduce[0][0]         
__________________________________________________________________________________________________
activation_519 (Activation)     (None, 16, 16, 256)  0           conv5_c_1x1_reduce/bn[0][0]      
__________________________________________________________________________________________________
conv5_c_3x3 (Conv2D)            (None, 16, 16, 256)  589824      activation_519[0][0]             
__________________________________________________________________________________________________
conv5_c_3x3/bn (BatchNormalizat (None, 16, 16, 256)  1024        conv5_c_3x3[0][0]                
__________________________________________________________________________________________________
activation_520 (Activation)     (None, 16, 16, 256)  0           conv5_c_3x3/bn[0][0]             
__________________________________________________________________________________________________
conv5_c_1x1_increase (Conv2D)   (None, 16, 16, 512)  131072      activation_520[0][0]             
__________________________________________________________________________________________________
conv5_c_1x1_increase/bn (BatchN (None, 16, 16, 512)  2048        conv5_c_1x1_increase[0][0]       
__________________________________________________________________________________________________
add_164 (Add)                   (None, 16, 16, 512)  0           conv5_c_1x1_increase/bn[0][0]    
                                                                 activation_518[0][0]             
__________________________________________________________________________________________________
activation_521 (Activation)     (None, 16, 16, 512)  0           add_164[0][0]                    
__________________________________________________________________________________________________
mpool2 (MaxPooling2D)           (None, 7, 16, 512)   0           activation_521[0][0]             
__________________________________________________________________________________________________
x_fc (Conv2D)                   (None, 1, 16, 512)   1835520     mpool2[0][0]                     
__________________________________________________________________________________________________
gvlad_center_assignment (Conv2D (None, 1, 16, 10)    35850       mpool2[0][0]                     
__________________________________________________________________________________________________
gvlad_pool (VladPooling)        (None, 4096)         5120        x_fc[0][0]                       
                                                                 gvlad_center_assignment[0][0]    
__________________________________________________________________________________________________
fc6 (Dense)                     (None, 512)          2097664     gvlad_pool[0][0]                 
__________________________________________________________________________________________________
lambda_9 (Lambda)               (None, 512)          0           fc6[0][0]                        
__________________________________________________________________________________________________
prediction (Dense)              (None, 5994)         3068928     lambda_9[0][0]                   
==================================================================================================
Total params: 10,747,338
Trainable params: 10,733,322
Non-trainable params: 14,016
__________________________________________________________________________________________________
